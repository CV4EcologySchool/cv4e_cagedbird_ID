# Here's where you define experiment-specific hyperparameters.
# You can also create lists and group parameters together into nested sub-parts.
# In Python, this is all read as a dict.

# environment/computational parameters
seed: 32678456782       # random number generator seed (long integer value)
device: cuda
num_workers: 4

# dataset parameters
data_root: /home/sicily/cv4e_cagedbird_ID/data
num_classes: 29

# training hyperparameters
image_size: [224, 224] # [224, 224] keep it as [224] or [224, ] if you want to keep the aspect ratio the same
num_epochs: 50 # 200, dataset is currently unbalanced, wa 10 and then 20
batch_size: 128
learning_rate: 0.005 # was 0.001 before (for ALL previous experiments) so multiply lr by 10 to see if you can get the val to plateau earlier than 100 epochs, reduce LR on plateau
parameter: 
weight_decay: 0.001
scheduler_step_size: 10
# the number of epochs when the lr updates
scheduler_gamma: 1
# if gamma: 1 it will times this by the lr, so it is the same as using no scheduling

# Comet ML experiment saving details
experiment_name: a-resnet18_d-checked_b-128_n-50_padded_images
# add the scheduler step
project_name: cagedbird-classifier
api_key: 6D79SKeAIuSjteySwQwqx96nq
